********** Args **********
seed: 42
batch_size: 12
hidden_size: 768
n_class: 97
num_workers: 2
epochs: 5
train: False
bert_model: snunlp/KR-Medium
max_token_len: 512
train_data: /content/drive/MyDrive/Korean_RE/data/data_split/train.csv
val_data: /content/drive/MyDrive/Korean_RE/data/data_split/val.csv
test_data: /content/drive/MyDrive/Korean_RE/data/data_split/test.csv
relation_list: /content/drive/MyDrive/Korean_RE/data/relation/relation_list.txt
save_dir: /content/drive/MyDrive/Korean_RE/ckpt/whole_data
log_file: /content/drive/MyDrive/Korean_RE/log/whole_data_result.txt
mode: ALLCC

********** Accuracy per threshold **********
0.1	0.9989
0.2	0.9991
0.3	0.9992
0.4	0.9992
0.5	0.9992
0.6	0.9993
0.7	0.9992
0.8	0.9992
0.9	0.9991

********** Max Threshold: 0.6000000000000001 **********

********** Classification Report **********
라벨이름	precision	recall  	f1-score	support
P17	0.984375	0.982678	0.983526	23785
P131	0.984151	0.978608	0.981372	15800
P530	0.997568	0.993625	0.995592	7843
P150	0.996266	0.991000	0.993626	7000
P47	0.986457	0.981774	0.984110	6529
P106	0.994230	0.991755	0.992991	6428
P27	0.937300	0.954597	0.945869	6123
P461	0.995291	0.994552	0.994921	4038
P279	0.953422	0.933503	0.943357	3925
P495	0.942153	0.954534	0.948303	3805
P641	0.995536	0.994980	0.995258	3586
P156	0.988677	0.962576	0.975452	3447
P155	0.978074	0.961830	0.969884	3432
P527	0.950456	0.942610	0.946517	2544
P361	0.924124	0.927566	0.925842	2416
P1376	0.959259	0.956728	0.957992	1895
P36	0.981303	0.979638	0.980470	1768
P118	0.999226	0.996911	0.998067	1295
P1889	0.922652	0.918303	0.920472	1273
P31	0.938723	0.868504	0.902249	1270
P175	0.946541	0.912121	0.929012	990
P463	0.943311	0.943311	0.943311	882
P54	0.991935	0.978409	0.985126	880
P138	0.909091	0.869565	0.888889	828
P81	0.991283	0.992519	0.991900	802
P40	0.943723	0.868526	0.904564	753
P159	0.945988	0.829499	0.883922	739
P136	0.967096	0.938889	0.952784	720
P171	0.993865	0.978852	0.986301	662
P22	0.951342	0.885938	0.917476	640
P26	0.922078	0.911717	0.916868	623
P3373	0.896607	0.893720	0.895161	621
P50	0.966957	0.909984	0.937605	611
P30	0.998305	0.991582	0.994932	594
P1532	0.848291	0.669477	0.748351	593
P178	0.873905	0.842905	0.858126	592
P413	1.000000	1.000000	1.000000	590
P800	0.968284	0.913732	0.940217	568
P1365	0.958333	0.892416	0.924201	567
P276	0.862069	0.772727	0.814957	550
P1366	0.963340	0.882463	0.921130	536
P19	0.878882	0.533962	0.664319	530
P449	0.940594	0.908222	0.924125	523
P710	0.973469	0.954000	0.963636	500
P2936	0.993865	0.989817	0.991837	491
P1001	0.980088	0.919087	0.948608	482
P140	0.977427	0.962222	0.969765	450
P206	0.964602	0.973214	0.968889	448
P1056	0.953917	0.943052	0.948454	439
P20	0.788462	0.777251	0.782816	422
P6	0.948235	0.964115	0.956109	418
P123	0.920398	0.887290	0.903541	417
P1830	0.942857	0.802920	0.867280	411
P127	0.900000	0.619165	0.733624	407
P1659	0.997455	0.987406	0.992405	397
P112	0.926893	0.907928	0.917313	391
P101	0.976119	0.836317	0.900826	391
P3095	0.992147	0.992147	0.992147	382
P749	0.829971	0.825215	0.827586	349
P1696	1.000000	0.997101	0.998549	345
P137	0.926518	0.852941	0.888208	340
P2789	0.982143	0.976331	0.979228	338
P706	0.940199	0.842262	0.888540	336
P3842	0.996865	0.972477	0.984520	327
P39	0.912752	0.871795	0.891803	312
P425	0.986842	0.990099	0.988468	303
P1336	0.983108	0.966777	0.974874	301
P108	0.833333	0.769231	0.800000	299
P172	0.972881	0.963087	0.967960	298
P737	0.972973	0.863014	0.914701	292
P176	0.895683	0.864583	0.879859	288
P102	0.989247	0.961672	0.975265	287
P35	0.955882	0.909091	0.931900	286
P3730	0.996183	0.992395	0.994286	263
P1687	0.995984	0.988048	0.992000	251
P945	0.883117	0.836066	0.858947	244
P264	0.991525	0.962963	0.977035	243
P161	0.909524	0.826840	0.866213	231
P69	0.855769	0.770563	0.810934	231
P190	0.985577	0.907080	0.944700	226
P355	0.887387	0.871681	0.879464	226
P2341	0.947619	0.888393	0.917051	224
P664	0.966981	0.949074	0.957944	216
P407	0.967136	0.976303	0.971698	211
P793	0.966507	0.961905	0.964200	210
P840	0.940741	0.628713	0.753709	202
P1441	0.955056	0.841584	0.894737	202
P607	0.974093	0.964103	0.969072	195
P197	1.000000	1.000000	1.000000	194
P205	0.972067	0.920635	0.945652	189
P162	0.645390	0.526012	0.579618	173
P807	0.954802	0.994118	0.974063	170
P1269	0.967105	0.864706	0.913043	170
P170	0.909091	0.654762	0.761246	168
P97	0.909677	0.849398	0.878505	166
P750	0.810219	0.676829	0.737542	164
P551	0.927711	0.500000	0.649789	154
micro avg	0.971327	0.955637	0.963418	139666
macro avg	0.946440	0.897738	0.919374	139666
weighted avg	0.970653	0.955637	0.962525	139666
samples avg	0.954303	0.955637	0.954747	139666

***********************************************************************
단순 정확도(Accuracy): 95.2974
조항별 정확도를 고려한 전체 정확도(Weighted Avg의 F1 Accuracy): 96.2525
***********************************************************************
