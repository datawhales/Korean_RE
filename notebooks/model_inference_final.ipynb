{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handmade-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rubber-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easydict\n",
    "import argparse\n",
    "import json\n",
    "from pororo import Pororo\n",
    "from itertools import permutations\n",
    "from transformers import BertTokenizer\n",
    "from transformers import logging\n",
    "import requests\n",
    "from korre.model import KREModel\n",
    "\n",
    "\n",
    "class KorRE:\n",
    "    def __init__(self):\n",
    "        self.args = easydict.EasyDict({'bert_model': 'datawhales/korean-relation-extraction', 'mode': 'ALLCC', \n",
    "                                        'n_class': 97, 'max_token_len': 512, 'max_acc_threshold': 0.6})\n",
    "        self.ner_module = Pororo(task='ner', lang='ko')\n",
    "        \n",
    "        logging.set_verbosity_error()\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.args.bert_model)\n",
    "        \n",
    "        # # entity markers tokens\n",
    "        # special_tokens_dict = {'additional_special_tokens': ['[E1]', '[/E1]', '[E2]', '[/E2]']}\n",
    "        # num_added_toks = self.tokenizer.add_special_tokens(special_tokens_dict)   # num_added_toks: 4\n",
    "        \n",
    "        self.trained_model = self.__get_model()\n",
    "        \n",
    "        # relation id to label\n",
    "        r = requests.get('https://raw.githubusercontent.com/datawhales/Korean_RE/main/data/relation/relid2label.json')\n",
    "        self.relid2label = json.loads(r.text)\n",
    "        \n",
    "        # relation list\n",
    "        self.relation_list = list(self.relid2label.keys())\n",
    "\n",
    "        # device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.trained_model = self.trained_model.to(self.device)\n",
    "        \n",
    "    def __get_model(self):\n",
    "        \"\"\" 사전학습된 한국어 관계 추출 모델을 로드하는 함수.\n",
    "        \"\"\"\n",
    "        # trained_model = KREModel.load_from_checkpoint('./ckpt/best-checkpoint.ckpt', args=self.args)\n",
    "        trained_model = torch.load('../final/entire_model.pth')\n",
    "        trained_model.eval()\n",
    "#         trained_model.freeze()\n",
    "\n",
    "        return trained_model\n",
    "    \n",
    "    def __idx2relid(self, idx_list):\n",
    "        \"\"\" onehot label에서 1인 위치 인덱스 리스트를 relation id 리스트로 변환하는 함수.\n",
    "        \n",
    "        Example:\n",
    "            relation_list = ['P17', 'P131', 'P530', ...] 일 때,\n",
    "            __idx2relid([0, 2]) => ['P17', 'P530'] 을 반환.\n",
    "        \"\"\"\n",
    "        label_out = []\n",
    "\n",
    "        for idx in idx_list:\n",
    "            label = self.relation_list[idx]\n",
    "            label_out.append(label)\n",
    "            \n",
    "        return label_out\n",
    "\n",
    "    def pororo_ner(self, sentence: str):\n",
    "        \"\"\" pororo의 ner 모듈을 이용하여 그대로 반환하는 함수.\n",
    "        \"\"\"\n",
    "        return self.ner_module(sentence)\n",
    "        \n",
    "    def ner(self, sentence: str):\n",
    "        \"\"\" 주어진 문장에서 pororo의 ner 모듈을 이용해 개체명 인식을 수행하고 각 개체의 인덱스 위치를 함께 반환하는 함수.\n",
    "        \"\"\"\n",
    "        ner_result = self.ner_module(sentence)\n",
    "        ner_result = [(item[0], item[1], len(item[0])) for item in ner_result]\n",
    "        \n",
    "        modified_list = []\n",
    "        tmp_cnt = 0\n",
    "\n",
    "        for item in ner_result:\n",
    "            modified_list.append((item[0], item[1], [tmp_cnt, tmp_cnt + item[2]]))\n",
    "            tmp_cnt += item[2]\n",
    "        \n",
    "        ent_list = [item for item in modified_list if item[1] != 'O']\n",
    "        \n",
    "        return ent_list\n",
    "    \n",
    "    def get_all_entity_pairs(self, sentence: str) -> list:\n",
    "        \"\"\" 주어진 문장에서 개체명 인식을 통해 모든 가능한 [문장, subj_range, obj_range]의 리스트를 반환하는 함수.\n",
    "        \n",
    "        Example:\n",
    "            sentence = '모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.'\n",
    "            \n",
    "        Return: \n",
    "            [(('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
    "             (('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('안드로이드', 'TERM', [32, 37])),\n",
    "             (('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('스마트폰', 'TERM', [38, 42])),\n",
    "             (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
    "             (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('안드로이드', 'TERM', [32, 37])),\n",
    "             (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('스마트폰', 'TERM', [38, 42])),\n",
    "             (('안드로이드', 'TERM', [32, 37]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
    "             (('안드로이드', 'TERM', [32, 37]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
    "             (('안드로이드', 'TERM', [32, 37]), ('스마트폰', 'TERM', [38, 42])),\n",
    "             (('스마트폰', 'TERM', [38, 42]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
    "             (('스마트폰', 'TERM', [38, 42]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
    "             (('스마트폰', 'TERM', [38, 42]), ('안드로이드', 'TERM', [32, 37]))]\n",
    "        \"\"\"\n",
    "        # 너무 긴 문장의 경우 500자 이내로 자름\n",
    "        if len(sentence) >= 500:\n",
    "            sentence = sentence[:499]\n",
    "        \n",
    "        ner_result = self.ner_module(sentence)\n",
    "        \n",
    "        # 인식된 각 개체명의 range 계산\n",
    "        ner_result = [(item[0], item[1], len(item[0])) for item in ner_result]\n",
    "        \n",
    "        modified_list = []\n",
    "        tmp_cnt = 0\n",
    "\n",
    "        for item in ner_result:\n",
    "            modified_list.append((item[0], item[1], [tmp_cnt, tmp_cnt + item[2]]))\n",
    "            tmp_cnt += item[2]\n",
    "            \n",
    "        # NER\n",
    "        ent_list = [item for item in modified_list if item[1] != 'O']\n",
    "        \n",
    "        result_list = []\n",
    "\n",
    "        pairs = list(permutations(ent_list, 2))\n",
    "        \n",
    "        return pairs\n",
    "\n",
    "    def get_all_inputs(self, sentence: str) -> list:\n",
    "        \"\"\" 주어진 문장에서 관계 추출 모델에 통과시킬 수 있는 모든 input의 리스트를 반환하는 함수.\n",
    "        \n",
    "        Example:\n",
    "            sentence = '모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.'\n",
    "            \n",
    "        Return:\n",
    "            [['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [12, 21]],\n",
    "            ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [32, 37]],\n",
    "            ..., ]\n",
    "        \"\"\"\n",
    "        pairs = self.get_all_entity_pairs(sentence)\n",
    "        return [[sentence, ent_subj[2], ent_obj[2]] for ent_subj, ent_obj in pairs]\n",
    "\n",
    "    def entity_markers_added(self, sentence: str, subj_range: list, obj_range: list) -> str:\n",
    "        \"\"\" 문장과 관계를 구하고자 하는 두 개체의 인덱스 범위가 주어졌을 때 entity marker token을 추가하여 반환하는 함수.\n",
    "        \n",
    "        Example:\n",
    "            sentence = '모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.'\n",
    "            subj_range = [0, 10]   # sentence[subj_range[0]: subj_range[1]] => '모토로라 레이저 M'\n",
    "            obj_range = [12, 21]   # sentence[obj_range[0]: obj_range[1]] => '모토로라 모빌리티'\n",
    "            \n",
    "        Return:\n",
    "            '[E1] 모토로라 레이저 M [/E1] 는  [E2] 모토로라 모빌리티 [/E2] 에서 제조/판매하는 안드로이드 스마트폰이다.'\n",
    "        \"\"\"\n",
    "        result_sent = ''\n",
    "        \n",
    "        for i, char in enumerate(sentence):\n",
    "            if i == subj_range[0]:\n",
    "                result_sent += ' [E1] '\n",
    "            elif i == subj_range[1]:\n",
    "                result_sent += ' [/E1] '\n",
    "            if i == obj_range[0]:\n",
    "                result_sent += ' [E2] '\n",
    "            elif i == obj_range[1]:\n",
    "                result_sent += ' [/E2] '\n",
    "            result_sent += sentence[i]\n",
    "        if subj_range[1] == len(sentence):\n",
    "            result_sent += ' [/E1]'\n",
    "        elif obj_range[1] == len(sentence):\n",
    "            result_sent += ' [/E2]'\n",
    "        \n",
    "        return result_sent.strip()\n",
    "\n",
    "    def infer(self, sentence: str, subj_range=None, obj_range=None, entity_markers_included=False):\n",
    "        \"\"\" 입력받은 문장에 대해 관계 추출 태스크를 수행하는 함수.\n",
    "        \"\"\"\n",
    "        # entity marker token이 포함된 경우\n",
    "        if entity_markers_included:\n",
    "            # subj, obj name 구하기\n",
    "            tmp_input_ids = self.tokenizer(sentence)['input_ids']\n",
    "\n",
    "            if tmp_input_ids.count(20000) != 1 or tmp_input_ids.count(20001) != 1 or \\\n",
    "            tmp_input_ids.count(20002) != 1 or tmp_input_ids.count(20003) != 1:\n",
    "                raise Exception(\"Incorrect number of entity marker tokens('[E1]', '[/E1]', '[E2]', '[/E2]').\")\n",
    "\n",
    "            subj_start_id, subj_end_id = tmp_input_ids.index(20000), tmp_input_ids.index(20001)\n",
    "            obj_start_id, obj_end_id = tmp_input_ids.index(20002), tmp_input_ids.index(20003)\n",
    "\n",
    "            subj_name = self.tokenizer.decode(tmp_input_ids[subj_start_id+1:subj_end_id])\n",
    "            obj_name = self.tokenizer.decode(tmp_input_ids[obj_start_id+1:obj_end_id])\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                             sentence,\n",
    "                             add_special_tokens=True,\n",
    "                             max_length=self.args.max_token_len,\n",
    "                             return_token_type_ids=False,\n",
    "                             padding='max_length',\n",
    "                             truncation=True,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors=\"pt\")\n",
    "\n",
    "            input_ids = encoding['input_ids'].to(self.device)\n",
    "            mask = encoding['attention_mask'].to(self.device)\n",
    "\n",
    "            _, prediction = self.trained_model(input_ids, mask)\n",
    "\n",
    "            predictions = [prediction.flatten()]\n",
    "            predictions = torch.stack(predictions).detach().cpu()\n",
    "\n",
    "            y_pred = predictions.numpy()\n",
    "            upper, lower = 1, 0\n",
    "            y_pred = np.where(y_pred > self.args.max_acc_threshold, upper, lower)\n",
    "\n",
    "            preds_list = []\n",
    "\n",
    "            for i in range(len(y_pred)):\n",
    "                class_pred = self.__idx2relid(np.where(y_pred[i]==1)[0])\n",
    "                preds_list.append(class_pred)\n",
    "\n",
    "            preds_list = preds_list[0]\n",
    "\n",
    "            pred_rel_list = [self.relid2label[pred] for pred in preds_list]               \n",
    "\n",
    "            return [(subj_name, obj_name, pred_rel) for pred_rel in pred_rel_list]\n",
    "\n",
    "        # entity_markers_included=False인 경우\n",
    "        else:\n",
    "            # entity marker가 문장에 포함된 경우\n",
    "            tmp_input_ids = self.tokenizer(sentence)['input_ids']\n",
    "            \n",
    "            if tmp_input_ids.count(20000) >= 1 or tmp_input_ids.count(20001) >= 1 or \\\n",
    "            tmp_input_ids.count(20002) >= 1 or tmp_input_ids.count(20003) >= 1:\n",
    "                raise Exception(\"Entity marker tokens already exist in the input sentence. Try 'entity_markers_included=True'.\")\n",
    "            \n",
    "            # subj range와 obj range가 주어진 경우\n",
    "            if subj_range is not None and obj_range is not None:\n",
    "                # add entity markers\n",
    "                converted_sent = self.entity_markers_added(sentence, subj_range, obj_range)\n",
    "\n",
    "                encoding = self.tokenizer.encode_plus(\n",
    "                             converted_sent,\n",
    "                             add_special_tokens=True,\n",
    "                             max_length=self.args.max_token_len,\n",
    "                             return_token_type_ids=False,\n",
    "                             padding='max_length',\n",
    "                             truncation=True,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors=\"pt\")\n",
    "                \n",
    "                input_ids = encoding['input_ids'].to(self.device)\n",
    "                mask = encoding['attention_mask'].to(self.device)\n",
    "                \n",
    "                _, prediction = self.trained_model(input_ids, mask)\n",
    "\n",
    "                predictions = [prediction.flatten()]\n",
    "                predictions = torch.stack(predictions).detach().cpu()\n",
    "\n",
    "                y_pred = predictions.numpy()\n",
    "                upper, lower = 1, 0\n",
    "                y_pred = np.where(y_pred > self.args.max_acc_threshold, upper, lower)\n",
    "\n",
    "                preds_list = []\n",
    "\n",
    "                for i in range(len(y_pred)):\n",
    "                    class_pred = self.__idx2relid(np.where(y_pred[i]==1)[0])\n",
    "                    preds_list.append(class_pred)\n",
    "\n",
    "                preds_list = preds_list[0]\n",
    "\n",
    "                pred_rel_list = [self.relid2label[pred] for pred in preds_list]\n",
    "\n",
    "                return [(sentence[subj_range[0]:subj_range[1]], sentence[obj_range[0]:obj_range[1]], pred_rel) for pred_rel in pred_rel_list]\n",
    "\n",
    "            # 문장만 주어진 경우: 모든 경우에 대해 inference 수행\n",
    "            else:\n",
    "                input_list = self.get_all_inputs(sentence)\n",
    "\n",
    "                converted_sent_list = [self.entity_markers_added(*input_list[i]) for i in range(len(input_list))]\n",
    "\n",
    "                encoding_list = []\n",
    "\n",
    "                for i, converted_sent in enumerate(converted_sent_list):\n",
    "                    tmp_encoding = self.tokenizer.encode_plus(\n",
    "                                            converted_sent,\n",
    "                                            add_special_tokens=True,\n",
    "                                             max_length=self.args.max_token_len,\n",
    "                                             return_token_type_ids=False,\n",
    "                                             padding='max_length',\n",
    "                                             truncation=True,\n",
    "                                             return_attention_mask=True,\n",
    "                                             return_tensors=\"pt\"\n",
    "                                        )\n",
    "                    encoding_list.append(tmp_encoding)\n",
    "\n",
    "                predictions = []\n",
    "\n",
    "                for i, item in enumerate(encoding_list):\n",
    "                    _, prediction = self.trained_model(\n",
    "                        item['input_ids'].to(self.device),\n",
    "                        item['attention_mask'].to(self.device)\n",
    "                    )\n",
    "\n",
    "                    predictions.append(prediction.flatten())\n",
    "\n",
    "                if predictions:\n",
    "                    predictions = torch.stack(predictions).detach().cpu()\n",
    "\n",
    "                    y_pred = predictions.numpy()\n",
    "                    upper, lower = 1, 0\n",
    "                    y_pred = np.where(y_pred > self.args.max_acc_threshold, upper, lower)\n",
    "\n",
    "                    preds_list = []\n",
    "                    for i in range(len(y_pred)):\n",
    "                        class_pred = self.__idx2relid(np.where(y_pred[i]==1)[0])\n",
    "                        preds_list.append(class_pred)\n",
    "\n",
    "                    result_list = []\n",
    "                    for i, input_i in enumerate(input_list):\n",
    "                        tmp_subj_range, tmp_obj_range = input_i[1], input_i[2]\n",
    "                        result_list.append((sentence[tmp_subj_range[0]:tmp_subj_range[1]], sentence[tmp_obj_range[0]:tmp_obj_range[1]], preds_list[i]))\n",
    "\n",
    "                    final_list = []\n",
    "                    for tmp_subj, tmp_obj, tmp_list in result_list:\n",
    "                        for i in range(len(tmp_list)):\n",
    "                            final_list.append((tmp_subj, tmp_obj, tmp_list[i]))\n",
    "\n",
    "                    return [(item[0], item[1], self.relid2label[item[2]]) for item in final_list]\n",
    "\n",
    "                else: return []\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "major-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "korre = KorRE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sixth-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = '아이폰은 애플에서 만들어진 스마트폰이다.'\n",
    "sent2 = '모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.'\n",
    "sent3 = '징크스는 리그오브레전드 캐릭터이다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "extraordinary-level",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', 'ARTIFACT'),\n",
       " ('은', 'O'),\n",
       " (' ', 'O'),\n",
       " ('애플', 'ORGANIZATION'),\n",
       " ('에서', 'O'),\n",
       " (' ', 'O'),\n",
       " ('만들어진', 'O'),\n",
       " (' ', 'O'),\n",
       " ('스마트폰', 'TERM'),\n",
       " ('이다.', 'O')]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.pororo_ner(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "coated-volleyball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', 'ARTIFACT'),\n",
       " ('는', 'O'),\n",
       " (' ', 'O'),\n",
       " ('모토로라 모빌리티', 'ORGANIZATION'),\n",
       " ('에서', 'O'),\n",
       " (' ', 'O'),\n",
       " ('제조/판매하는', 'O'),\n",
       " (' ', 'O'),\n",
       " ('안드로이드', 'TERM'),\n",
       " (' ', 'O'),\n",
       " ('스마트폰', 'TERM'),\n",
       " ('이다.', 'O')]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.pororo_ner(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "tamil-orange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('징크스는', 'O'),\n",
       " (' ', 'O'),\n",
       " ('리그오브레전드', 'ARTIFACT'),\n",
       " (' ', 'O'),\n",
       " ('캐릭터이다.', 'O')]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.pororo_ner(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "blind-driver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', 'ARTIFACT', [0, 3]),\n",
       " ('애플', 'ORGANIZATION', [5, 7]),\n",
       " ('스마트폰', 'TERM', [15, 19])]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.ner(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "roman-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', 'ARTIFACT', [0, 10]),\n",
       " ('모토로라 모빌리티', 'ORGANIZATION', [12, 21]),\n",
       " ('안드로이드', 'TERM', [32, 37]),\n",
       " ('스마트폰', 'TERM', [38, 42])]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.ner(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "general-trail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('리그오브레전드', 'ARTIFACT', [5, 12])]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.ner(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "entertaining-paris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('아이폰', 'ARTIFACT', [0, 3]), ('애플', 'ORGANIZATION', [5, 7])),\n",
       " (('아이폰', 'ARTIFACT', [0, 3]), ('스마트폰', 'TERM', [15, 19])),\n",
       " (('애플', 'ORGANIZATION', [5, 7]), ('아이폰', 'ARTIFACT', [0, 3])),\n",
       " (('애플', 'ORGANIZATION', [5, 7]), ('스마트폰', 'TERM', [15, 19])),\n",
       " (('스마트폰', 'TERM', [15, 19]), ('아이폰', 'ARTIFACT', [0, 3])),\n",
       " (('스마트폰', 'TERM', [15, 19]), ('애플', 'ORGANIZATION', [5, 7]))]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_entity_pairs(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "endless-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21]))\n",
      "(('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('안드로이드', 'TERM', [32, 37]))\n",
      "(('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('스마트폰', 'TERM', [38, 42]))\n",
      "(('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10]))\n",
      "(('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('안드로이드', 'TERM', [32, 37]))\n",
      "(('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('스마트폰', 'TERM', [38, 42]))\n",
      "(('안드로이드', 'TERM', [32, 37]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10]))\n",
      "(('안드로이드', 'TERM', [32, 37]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21]))\n",
      "(('안드로이드', 'TERM', [32, 37]), ('스마트폰', 'TERM', [38, 42]))\n",
      "(('스마트폰', 'TERM', [38, 42]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10]))\n",
      "(('스마트폰', 'TERM', [38, 42]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21]))\n",
      "(('스마트폰', 'TERM', [38, 42]), ('안드로이드', 'TERM', [32, 37]))\n"
     ]
    }
   ],
   "source": [
    "for item in korre.get_all_entity_pairs(sent2):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "foster-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in korre.get_all_entity_pairs(sent3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "parental-boston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아이폰은 애플에서 만들어진 스마트폰이다.', [0, 3], [5, 7]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [0, 3], [15, 19]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [5, 7], [0, 3]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [5, 7], [15, 19]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [15, 19], [0, 3]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [15, 19], [5, 7]]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "nominated-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [32, 37]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [32, 37]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [32, 37]]]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs(sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "informed-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs(sent3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "several-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] 아이폰 [/E1] 은  [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.\n",
      "[E1] 아이폰 [/E1] 은 애플에서 만들어진  [E2] 스마트폰 [/E2] 이다.\n",
      "[E2] 아이폰 [/E2] 은  [E1] 애플 [/E1] 에서 만들어진 스마트폰이다.\n",
      "아이폰은  [E1] 애플 [/E1] 에서 만들어진  [E2] 스마트폰 [/E2] 이다.\n",
      "[E2] 아이폰 [/E2] 은 애플에서 만들어진  [E1] 스마트폰 [/E1] 이다.\n",
      "아이폰은  [E2] 애플 [/E2] 에서 만들어진  [E1] 스마트폰 [/E1] 이다.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(korre.get_all_inputs(sent1))):\n",
    "    print(korre.entity_markers_added(*korre.get_all_inputs(sent1)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "casual-phoenix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('아이폰', '애플', '제조사')]\n",
      "[('아이폰', '스마트폰', '다음의 하위 개념임')]\n",
      "[('애플', '아이폰', '제품')]\n",
      "[('애플', '스마트폰', '제품')]\n",
      "[]\n",
      "[('스마트폰', '애플', '제조사')]\n"
     ]
    }
   ],
   "source": [
    "for i in korre.get_all_inputs(sent1):\n",
    "    print(korre.infer(*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-quick",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f0b2a4c746d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkorre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkorre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkorre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_markers_added\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkorre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_markers_included\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c0da67fd1180>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, sentence, subj_range, obj_range, entity_markers_included)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mpreds_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mpred_rel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relation_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred_rel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_rel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-c0da67fd1180>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mpreds_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mpred_rel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelid2label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'relation_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_rel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred_rel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_rel_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "for i in range(len(korre.get_all_inputs(sent1))):\n",
    "    print(korre.infer(korre.entity_markers_added(*korre.get_all_inputs(sent1)[i]), entity_markers_included=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "known-commodity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', '애플', '해당 개체의 제조사(manufacturer)')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', entity_markers_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cathedral-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [5, 8], [22, 24]],\n",
       " ['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [5, 8], [39, 43]],\n",
       " ['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [22, 24], [5, 8]],\n",
       " ['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [22, 24], [39, 43]],\n",
       " ['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [39, 43], [5, 8]],\n",
       " ['[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', [39, 43], [22, 24]]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = '[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.'\n",
    "korre.get_all_inputs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "substantial-romania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', '애플', '해당 개체의 제조사(manufacturer)')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer(sent, entity_markers_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-delight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "inside-essex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', '애플', '해당 개체의 제조사(manufacturer)')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('[E1] 아이폰[/E1] 은  [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.', entity_markers_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "flexible-organization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('징크스', '리그오브레전드', '해당 개체가 다음 작품에 등장함(present in work)')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('[E1] 징크스[/E1]는 [E2]리그오브레전드 [/E2] 캐릭터이다.', entity_markers_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "alpine-acrobat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('사미라', '리그오브레전드', '해당 개체가 다음 작품에 등장함(present in work)'),\n",
       " ('리그오브레전드', '사미라', '해당 개체가 다음으로 이루어져 있음(has part)'),\n",
       " ('리그오브레전드', '총', '해당 개체가 다음으로 이루어져 있음(has part)'),\n",
       " ('리그오브레전드', '칼', '해당 개체가 다음으로 이루어져 있음(has part)'),\n",
       " ('총', '리그오브레전드', '다음과 다르지만 같은 의미인 것처럼 혼동되는 항목(different from)'),\n",
       " ('총', '칼', '다음과 다르지만 같은 의미인 것처럼 혼동되는 항목(different from)'),\n",
       " ('칼', '총', '다음과 다르지만 같은 의미인 것처럼 혼동되는 항목(different from)')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('사미라는 리그오브레전드 캐릭터로, 주로 총과 칼을 이용하여 전투를 하는 캐릭터이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "another-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://huggingface.co/datawhales/korean-relation-extraction/resolve/main/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "broke-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://huggingface.co/datawhales/korean-relation-extraction/resolve/main/pytorch_model.bin\" to /Users/datawhales/.cache/torch/hub/checkpoints/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740e8e9180724e09a6e13b833f40d29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/388M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only one file(not dir) is allowed in the zipfile",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-948e55da9173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://huggingface.co/datawhales/korean-relation-extraction/resolve/main/pytorch_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mmembers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_zipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Only one file(not dir) is allowed in the zipfile'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mcached_zipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mextraced_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only one file(not dir) is allowed in the zipfile"
     ]
    }
   ],
   "source": [
    "torch.hub.load_state_dict_from_url('https://huggingface.co/datawhales/korean-relation-extraction/resolve/main/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fiscal-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.7.0\n",
      "  Downloading torch-1.7.0-cp38-none-macosx_10_9_x86_64.whl (108.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 108.1 MB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/datawhales/opt/anaconda3/lib/python3.8/site-packages (from torch==1.7.0) (1.19.2)\n",
      "Requirement already satisfied: dataclasses in /Users/datawhales/opt/anaconda3/lib/python3.8/site-packages (from torch==1.7.0) (0.6)\n",
      "Requirement already satisfied: typing-extensions in /Users/datawhales/opt/anaconda3/lib/python3.8/site-packages (from torch==1.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: future in /Users/datawhales/opt/anaconda3/lib/python3.8/site-packages (from torch==1.7.0) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.6.0\n",
      "    Uninstalling torch-1.6.0:\n",
      "      Successfully uninstalled torch-1.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.7.0 requires torch==1.6.0, but you have torch 1.7.0 which is incompatible.\n",
      "pororo 0.4.2 requires torch==1.6.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "massive-lafayette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-bowling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-setup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "appreciated-luther",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Incorrect number of entity marker tokens('[E1]', '[/E1]', '[E2]', '[/E2]').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-cb650b66372a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkorre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 [E2] 스마트폰 [/E2] 이다.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_markers_included\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-189-de6073f5dea7>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, sentence, subj_range, obj_range, entity_markers_included)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20001\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20002\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20003\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Incorrect number of entity marker tokens('[E1]', '[/E1]', '[E2]', '[/E2]').\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0msubj_start_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubj_end_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Incorrect number of entity marker tokens('[E1]', '[/E1]', '[E2]', '[/E2]')."
     ]
    }
   ],
   "source": [
    "korre.infer('[E1] 아이폰 [/E1] 은 [E2] 애플 [/E2] 에서 만들어진 [E2] 스마트폰 [/E2] 이다.', entity_markers_included=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "athletic-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = '아이폰은 애플에서 만들어진 스마트폰이다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "manual-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', 'ARTIFACT'),\n",
       " ('은', 'O'),\n",
       " (' ', 'O'),\n",
       " ('애플', 'ORGANIZATION'),\n",
       " ('에서', 'O'),\n",
       " (' ', 'O'),\n",
       " ('만들어진', 'O'),\n",
       " (' ', 'O'),\n",
       " ('스마트폰', 'TERM'),\n",
       " ('이다.', 'O')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.pororo_ner(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "remarkable-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', 'ARTIFACT', [0, 3]),\n",
       " ('애플', 'ORGANIZATION', [5, 7]),\n",
       " ('스마트폰', 'TERM', [15, 19])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.ner(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "assumed-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('아이폰', 'ARTIFACT', [0, 3]), ('애플', 'ORGANIZATION', [5, 7])),\n",
       " (('아이폰', 'ARTIFACT', [0, 3]), ('스마트폰', 'TERM', [15, 19])),\n",
       " (('애플', 'ORGANIZATION', [5, 7]), ('아이폰', 'ARTIFACT', [0, 3])),\n",
       " (('애플', 'ORGANIZATION', [5, 7]), ('스마트폰', 'TERM', [15, 19])),\n",
       " (('스마트폰', 'TERM', [15, 19]), ('아이폰', 'ARTIFACT', [0, 3])),\n",
       " (('스마트폰', 'TERM', [15, 19]), ('애플', 'ORGANIZATION', [5, 7]))]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_entity_pairs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "undefined-machinery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아이폰은 애플에서 만들어진 스마트폰이다.', [0, 3], [5, 7]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [0, 3], [15, 19]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [5, 7], [0, 3]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [5, 7], [15, 19]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [15, 19], [0, 3]],\n",
       " ['아이폰은 애플에서 만들어진 스마트폰이다.', [15, 19], [5, 7]]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "occupational-consumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아이폰은 애플에서 만들어진 스마트폰이다.', [0, 3], [5, 7]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs(sent)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "inside-protein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[E1] 아이폰 [/E1] 은  [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.entity_markers_added(*korre.get_all_inputs(sent)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "curious-afternoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 in torch.tensor([[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "surrounded-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[E1]', '아이폰', '[/E1]', '은', '[E2]', '애플', '[/E2]', '에서', '만들어진', '스마트폰이다.']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sent = '[E1] 아이폰 [/E1] 은  [E2] 애플 [/E2] 에서 만들어진 스마트폰이다.'\n",
    "\n",
    "new_sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "entire-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아이폰 은 애플 에서 만들어진 스마트폰이다.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sent = '[E1]아이폰[/E1]은 [E2]애플 [/E2] 에서 만들어진 스마트폰이다.'\n",
    "korre.tokenizer.decode(korre.tokenizer(new_sent)['input_ids'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "proper-digest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.tokenizer(new_sent)['input_ids'].count(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_id, obj_id = [], []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "similar-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_start_id = korre.tokenizer(new_sent)['input_ids'].index(20000)\n",
    "subj_end_id = korre.tokenizer(new_sent)['input_ids'].index(20001)\n",
    "obj_start_id = korre.tokenizer(new_sent)['input_ids'].index(20002)\n",
    "obj_end_id = korre.tokenizer(new_sent)['input_ids'].index(20003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "signed-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_name = korre.tokenizer.decode(korre.tokenizer(new_sent)['input_ids'][subj_start_id+1:subj_end_id])\n",
    "obj_name = korre.tokenizer.decode(korre.tokenizer(new_sent)['input_ids'][obj_start_id+1:obj_end_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "stretch-residence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아이폰'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "under-manor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'애플'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "behavioral-shore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아이폰'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.tokenizer.decode([14071])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-joyce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-disclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-concentration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-failing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "french-instrument",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../kornre/pretrain.py:146: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  h_start_pos_tensor = (input_ids == 20000).nonzero()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', '모토로라 모빌리티', '제조사')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [12, 21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vocational-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', '안드로이드 스마트폰', '다음의 하위 개념임')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [32,42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "corrected-request",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('헥토르', '데이포', '친형제자매')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('헥토르는 동생 데이포보스가 자신을 도와주러 온 것으로 믿고 아킬레우스와 맞서 싸웠다.', [0, 3], [8,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "numerical-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', '모토로라 모빌리티', '제조사'),\n",
       " ('모토로라 레이저 M', '안드로이드', '다음의 하위 개념임'),\n",
       " ('모토로라 레이저 M', '스마트폰', '다음의 하위 개념임'),\n",
       " ('모토로라 모빌리티', '안드로이드', '제품'),\n",
       " ('모토로라 모빌리티', '스마트폰', '제품'),\n",
       " ('안드로이드', '스마트폰', '다음의 하위 개념임'),\n",
       " ('스마트폰', '모토로라 레이저 M', '다음으로 이루어져 있음'),\n",
       " ('스마트폰', '안드로이드', '다음과는 확실히 다름')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "turkish-robin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('모토로라 레이저 M', '스마트폰', '다음의 하위 개념임')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0,10],[38,42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-canada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sunrise-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [32, 37]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [0, 10], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [32, 37]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [12, 21], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [32, 37], [38, 42]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [0, 10]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [12, 21]],\n",
       " ['모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.', [38, 42], [32, 37]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_inputs('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "alpha-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('모토로라 레이저 M', 'ARTIFACT', [0, 10]),\n",
       "  ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
       " (('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('안드로이드', 'TERM', [32, 37])),\n",
       " (('모토로라 레이저 M', 'ARTIFACT', [0, 10]), ('스마트폰', 'TERM', [38, 42])),\n",
       " (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]),\n",
       "  ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
       " (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('안드로이드', 'TERM', [32, 37])),\n",
       " (('모토로라 모빌리티', 'ORGANIZATION', [12, 21]), ('스마트폰', 'TERM', [38, 42])),\n",
       " (('안드로이드', 'TERM', [32, 37]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
       " (('안드로이드', 'TERM', [32, 37]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
       " (('안드로이드', 'TERM', [32, 37]), ('스마트폰', 'TERM', [38, 42])),\n",
       " (('스마트폰', 'TERM', [38, 42]), ('모토로라 레이저 M', 'ARTIFACT', [0, 10])),\n",
       " (('스마트폰', 'TERM', [38, 42]), ('모토로라 모빌리티', 'ORGANIZATION', [12, 21])),\n",
       " (('스마트폰', 'TERM', [38, 42]), ('안드로이드', 'TERM', [32, 37]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.get_all_entity_pairs('모토로라 레이저 M는 모토로라 모빌리티에서 제조/판매하는 안드로이드 스마트폰이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "grateful-optimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아이폰', '애플', '제조사'),\n",
       " ('아이폰', '스마트폰', '다음의 하위 개념임'),\n",
       " ('애플', '아이폰', '제품'),\n",
       " ('애플', '스마트폰', '제품'),\n",
       " ('스마트폰', '애플', '제조사')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('아이폰은 애플에서 만들어진 스마트폰이다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "surprising-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('징크스는', 'O', 4),\n",
       " (' ', 'O', 1),\n",
       " ('리그오브레전드', 'ARTIFACT', 7),\n",
       " ('에', 'O', 1),\n",
       " (' ', 'O', 1),\n",
       " ('등장하는', 'O', 4),\n",
       " (' ', 'O', 1),\n",
       " ('캐릭터이다.', 'O', 6)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_sent = '징크스는 리그오브레전드에 등장하는 캐릭터이다.'\n",
    "korre.ner(tmp_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "nonprofit-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('징크스는 리그오브레전드에 등장하는 캐릭터이다.', [0,6],[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "korre.infer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "increased-fitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('징크스는 리그오브레전드 게임에 등장하는 캐릭터이다.', [0, 3], [14, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "elegant-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'리그오브레전드에'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'징크스는 리그오브레전드에 등장하는 캐릭터이다.'[5:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "shaped-saskatchewan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('명륜당', '앞', '반대 개념'),\n",
       " ('명륜당', '뒤', '명칭의 유래'),\n",
       " ('앞', '뒤', '반대 개념'),\n",
       " ('대성전', '뒤', '명칭의 유래'),\n",
       " ('뒤', '앞', '반대 개념')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korre.infer('공부하는 곳인 명륜당이 앞에, 사당인 대성전 뒤에 있는 전학후묘의 형태로 향교의 일반적인 배치를 따르고 있다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-render",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
